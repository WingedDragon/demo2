set spark.sql.shuffle.partitions=10;
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;

use dw;

insert overwrite table dw.release_customer partition(bdp_day)
select
    reqid,
    sessionid,
    device,
    source,
    ct,
    exts['code'] as code,
    bdp_day
from ods.release_sessions
where
    bdp_day = '${hiveconf:day_end}'
and
    status = '${hiveconf:status}'
