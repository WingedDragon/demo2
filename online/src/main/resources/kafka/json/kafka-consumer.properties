zk.connect=locahost:2181/kafka

#broker list
bootstrap.servers=node61:9092,node62:9092,node63:9092

#��Ϣ���л� IntegerDeserializer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

#Ĭ��������
group.id=sbBee99

#request.timeout.ms should be greater than session.timeout.ms and fetch.max.wait.ms
request.timeout.ms=60000

#consumer-kafka(broker controller)�������( <= 1/3 * session.timeout.ms) ����streaming����������batchDuration���е���
heartbeat.interval.ms=15000

#ʹ��consumer group�������ʱ, ���consumer����ʱ�䳬ʱ
# ʱ�䷶Χ��broker�����group.min.session.timeout.ms(6000) < ? < group.max.session.timeout.ms(30,0000)
session.timeout.ms=40000

#consumer ��ȡ�������ȴ�ʱ��(����Сfetch��¼�й�)
fetch.max.wait.ms=5000

## ��С��ȡ���ݴ�С
fetch.min.bytes=0

#ÿ�δ�kafka����ȡ����Ϣ���ߴ磨byte��,Ĭ��Ϊ50m (broker ��Ϣ���ߴ�message.max.bytes=1000012 10m, producer max.request.size=1048576 10m)
fetch.max.bytes=1000012

# ÿ�δӵ�����������ȡ����Ϣ���ߴ磨byte����Ĭ��Ϊ1M (broker message.max.bytes=1000012 10m )
max.partition.fetch.bytes=1000012

#ƫ���� [latest, earliest, none]
auto.offset.reset=earliest

#�Զ��ύ
enable.auto.commit=false
auto.commit.interval.ms= 2000

#consumer �������ȡ��¼
#max.poll.interval.ms=300000

#consumer �����ȡ��¼����
#max.poll.records=500

#compression type=none, gzip, snappy, lz4, producer
#compression.type=snappy

#consumer ��ȡ��¼�����С(-1 osĬ��ֵ)��ͬproducer receive.buffer.bytes=32768
#receive.buffer.bytes=65536

#consumer �������ݵĻ����С(-1 osĬ��)��ͬproducerһ��
#send.buffer.bytes=131072

#brokerԪ���ݼ��ʱ��
#metadata.max.age.ms=300000

#consumer ��¼offset����Ƶ��
#reconnect.backoff.ms=50



